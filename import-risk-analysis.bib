@techreport{burgman_comparing_2011,
  title = {Comparing {Biosecurity} {Risk} {Assessment} {Systems}},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0020/2220833/0709_final-report.pdf},
  abstract = {This report compares the import risk analysis systems deployed by Australia, Canada, New Zealand and the United States. It identifies the strengths and weaknesses of the different approaches, assesses their performance against international standards, and evaluates their implementation in a number of case studies. The report concludes with recommendations for desirable technical attributes of import risk analysis systems.},
  number = {0709},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Burgman, M and Mittinty, M and Whittle, P and Mengersen, K},
  month = mar,
  year = {2011},
  keywords = {import}
}

@techreport{burgman_demonstrating_2011,
  title = {Demonstrating risk analysis capabilities},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0009/2068668/0901_final-report.pdf},
  abstract = {This report implements a number of tools in the context of import risk analysis, some of which may be useful in training or in routine IRAs. Others may be useful in special cases, where particular features of the biology of a species or the circumstances of trade demand more detailed data collection and analysis. The purpose of this study was to demonstrate their capabilities, strengths and weaknesses for a hypothetical case study of insects on fruit. {\textbackslash}par The tools demonstrated in this study include scenario trees, structured protocols for questioning experts, methods for combining judgements, Monte Carlo, interval arithmetic, Bayes nets, probability bounds, spatial habitat modelling, cognitive maps, structured decision making, and surveillance and inspection tools.},
  number = {0901},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Burgman, M and Colyvan, M and Christian, R and Dobiecki, B and Elith, J and Fidler, F and Grant, N and Hauser, C and Hayes, K and Jones, S and Korb, K and Kuhnert, P and McBride, M and McCarthy, M and Nicholson, A and Robinson, A and Rout, T and Speirs-Bridge, A and Walshe, T},
  month = mar,
  year = {2011},
  keywords = {import}
}

@techreport{holliday_multi-pathway_2013,
  title = {Multi-pathway risk analysis: a case study of {Puccinia} psidii},
  url = {NA},
  number = {1206A},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Holliday, J},
  month = jun,
  year = {2013},
  keywords = {import}
}

@techreport{buckley_relative_2013,
  title = {Relative risk of different categories of imported biological products of animal origin},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0011/2068733/1101FOID1FR.pdf},
  abstract = {This report addresses the first of three components of ACERA Project No 1101F, being a review of the relative risk of different categories of imported biological products of animal origin, with recommendations for appropriate risk management measures for each category. This report provides a brief background to the project, and to the development of biosecurity conditions for biological products. reviews the biosecurity conditions for biological products as they currently exist, and categorises biological products by risk level and perceived effectiveness of current risk management measures. {\textbackslash}par The report found that in general, import conditions were managing biosecurity well. Where problems were occurring, the review identified six main causes of concern, which either alone or in combination, contributed to the majority of the identified problems.},
  number = {1101F ID1},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Buckley, D},
  month = aug,
  year = {2013},
  keywords = {import}
}

@techreport{barry_putting_2011,
  title = {Putting the quantitative into qualitative import risk assessments},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0019/2220823/0705b_final-report.pdf},
  abstract = {This report considers ways of reconciling qualitative and quantitative import risk assessment methods. There is a current view within some quarters that the use of these approaches requires a choice, and that the use of one approach precludes the use of the other. This is explored in this report, and ways of constructing the analysis from a logical foundation is developed. {\textbackslash}par Both approaches have been used previously in setting biosecurity policy and both have strengths and weaknesses. {\textbackslash}par Qualitative analysis is by far the predominant technique for performing import risk analysis. What constitutes a qualitative analysis varies widely. The analysis typically breaks up the risk pathway into steps such as entry, establishment and spread and then assesses the likelihood of these steps in some way, consistent with relevant international standards. {\textbackslash}par The repeatability of qualitative analysis can be debated for a number of reasons. First, its use of loosely defined terms such as Low, Medium and High means that there is ambiguity in their meaning. Second, questions in the analysis are often vaguely defined so there can be significant ambiguity in their definition. Third, techniques to combine the components of the assessment to reach an overall conclusion are typically ad hoc and not based on rigorous analysis. {\textbackslash}par Quantitative analysis offers the potential for greater transparency and interpretability. Given this, the approach also adds significant technical overheads and challenges when data is sparse or not available. The transparency of the approach invites high degrees of scrutiny which can complicate debate. A simple model can often fail to represent a complicated pattern of trade, leading to significant problems. In responding to this, models can become too complicated. Thus the use of quantitative methods does not, in itself, guarantee an improved analysis. {\textbackslash}par In this report we develop a quantitative import risk assessment model that is structured equivalently to qualitative import risk assessment models. This means that it will consider the steps of entry, establishment and spread. While the model is quantitative, in the sense that beliefs are expressed numerically, it is anticipated that it will typically be populated by expert-based assessments. We produce clear definitions for the quantities we are eliciting from the experts to ensure that conclusions from the process are logical and well founded. The advantage of the proposed approach is that it will produce an assessment consistent with international standards while clearly communicating its logical basis. {\textbackslash}par To do this we first describe the risk assessment problem. This highlights the complexity of the task and the diverse range of issues that need to be considered in making an assessment. We then consider the mechanics of probabilistic modelling of this system. While many authors suggest the ad hoc use of probability distributions for dealing with uncertainty, they rarely address the issue holistically, assessing how the results of the analysis map to the real world problem we are considering. With our understanding of the problem and the probabilistic framework we have developed, we consider issues in defining a quantitative analysis. We explore the complications that arise in the context of import risk analysis and show why simple models with strong independence assumptions can fail. Building on this analysis, we consider how an analysis concentrating on entry, establishment and spread could be framed in a quantitative way, and use this to propose a possible set of questions that could form the basis of a compact and rigorous expert-based import risk assessment system. The results are then applied to a simple example. {\textbackslash}par This is not an academic exercise. Lack of consistency in application of policies because of different interpretations of questions adds an element of randomness to the decision making process. This is because the outcome of the process could depend on the individuals involved rather than the details of the particular case. Ambiguity in the process also opens up the possibility of manipulation by interested parties. If the meaning of questions is not transparent, parties can make assumptions about the meanings which favour the outcome they want. The ambiguity provides an element of confusion to the debate that can potentially cloud communication. Finally, a clear mathematical framework is the foundation of any logical analysis. By laying this foundation we will be able to successfully and logically integrate appropriate tools for issues such as uncertainty analysis and expert elicitation. Without this, ambiguity could be potentially the biggest source of uncertainty, nullifying any potential benefits of new techniques trying to improve the outcomes of the biosecurity system. {\textbackslash}par This report is targeted at technical scientists and policy makers within biosecurity agencies. It will hopefully contribute to the debate and thinking about future development of import risk assessment techniques.},
  number = {0705B},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Barry, S},
  month = may,
  year = {2011},
  keywords = {import}
}

@techreport{barry_risk_2011,
  title = {Risk in complex pathways: {Propagation} of risk via zero inflated distributions and mixing},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0016/2220820/0705c_final-report.pdf},
  abstract = {Trade in commodities is rarely simple. Biosecurity risk material occurs in a variety of aggregations such as farms, containers and cases in the importation pathway. Assessing either the effectiveness of mitigation methods or the risk of incursion often requires considering this context. This report provides tools to support this assessment. We have proposed a mathematical/statistical method to model complex pathways which often occur in quantitative risk assessments in biosecurity. The mathematical models we have developed in this report include pest infection, mixing and inspection. Monte Carlo simulation techniques were used to analyse different stages of mixing and inspection. A worked example is given to illustrate the proposed modelling and analysis techniques. All the required computing functions have been coded in R and bundled together to form an R package called cpathway for easy adoption by decision makers.},
  number = {0705C},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Barry, S and Lin, X},
  month = may,
  year = {2011},
  keywords = {import}
}

@techreport{mccarthy_review_2007,
  title = {Review of the use of period of trade and trade volume in import risk analysis},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0004/2220817/0702.pdf},
  abstract = {The aim of this project was to review literature on the way in which risk is integrated over time and over volume of trade in Import Risk Assessments in Australia, to evaluate the implications of the approach, to compare it to the approaches used in other places and in other technical areas, and to evaluate potential avenues to improve application or communication. The report provides examples that illustrate assumptions of the current approach, and makes suggestions regarding the future use of tools for integrating and communicating probabilities.},
  number = {702},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {McCarthy, M and Burgman, M and Gordon, I},
  month = jun,
  year = {2007},
  keywords = {import}
}

@techreport{robinson_sampling_2014,
  title = {Sampling interceptions for identification.},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0006/2220819/1101E_FinalReport_01.pdf},
  abstract = {Background: DAFF intercepts pests, which may be regulated, and therefore actionable. The Operational Science Program (OSP) identifies the intercepted pests to determine their biosecurity status. The results of identification are recorded in the Incidents database. Not all pests are identified to the species level. A range of factors affects the amount of information available about any interception, so the Incidents database does not support statistical analysis, and DAFF cannot accurately evaluate the relative biosecurity risk posed by different pathways. {\textbackslash}par Overview: This project develops a sampling-based identification protocol which will result in identification data that supports statistical analysis. {\textbackslash}par Outcomes: The following outcomes arise from this report. 1. Overall OSP species level IDs have improved from around 25\% in the mid to late 1990’s to around 42\% in 2012. 2. The main improvements have come from specialised training and the publication of taxonomic keys and manuals. 3. To our knowledge, no international organization has been able to solve the problem of the non-representativeness of captured specimen data. 4. We develop a candidate scheme under which all intercepted specimens are submitted to OSP, and OSP implements a stratified sampling regime to determine which specimens to identify. {\textbackslash}par Recommendations: The following recommendations arise from this report. 1. Develop a trial of the sampling approach sketched herein (p. 24). 2. Free up OSP time to invest in spending time with border programs (p. 27). 3. Streamline Incidents data entry to enable more complete data capture (p. 26). 4. Improve feedback between OSP and border inspection staff (p. 27). 5. Maintain and increase specialised training of OSP staff with external experts (p. 27).},
  number = {1101E ID2},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Robinson, A and Maynard, G and Cannon, R},
  month = feb,
  year = {2014},
  keywords = {import}
}

@techreport{buckley_use_2013,
  title = {The use of manufacturer's declarations as a biosecurity control for the import of biologicals},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0018/2220822/1101FOID2FR.pdf},
  abstract = {In some cases, manufacturer’s declarations (MDs) are used in place of official Government-to-Government certification for ensuring biosecurity control over the import of biological products into Australia. For some categories of products, this has led to reports of alleged falsification of these documents. For other products, no such problems have been reported. {\textbackslash}par Examination of the way that MDs are used led to the development of strategies to minimise the risk of misuse of the MDs. These strategies range from banning use completely, to various methods of increasing the reliability of the documents, such as requiring endorsement of the MD by an official of the competent authority in the exporting country, or implementing a program of audits, inspections or tests to verify the content of the documents. {\textbackslash}par Import conditions for a number of different types of biological products were then reviewed, and the use of MDs in relation to those products was considered. Where necessary, recommendations were made to improve the biosecurity of the imported products. {\textbackslash}par Finally, a framework for the future application of manufacturer’s declarations was proposed.},
  number = {1101F ID2},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Buckley, D},
  month = aug,
  year = {2013},
  keywords = {import}
}

@techreport{hayes_uncertainty_2011,
  title = {Uncertainty and uncertainty analysis methods},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0010/2068651/0705a_final-report.pdf},
  abstract = {This report reviews uncertainty and uncertainty analysis methods in risk assessment, with a specific focus on issues related to import risk assessment. The report is motivated by the availability of qualitative and quantitative methods for import risk assessment. It examines how the challenges posed by uncertainty influence choices between these two approaches. The project’s terms of reference are to summarise and categorise the different sources of uncertainty in risk assessment problems, and review the practicality and applicability of a range of treatment methods. The report is intended for scientists and managers involved in, or contemplating the use of, qualitative or quantitative risk assessment. Whilst the report focusses on import risk assessment, readers from other application domains will find that much of the information and analysis presented here is relevant to them. {\textbackslash}par Uncertainty is a term used to encompass many concepts. It has been described, defined and categorised in many different ways, using different names for the same things and occasionally the same name for different things. This report identifies four basic sources of uncertainty: uncertainty that arises through the vagarious nature of language (linguistic uncertainty), the uncertainty created by our limited understanding of natural systems (epistemic uncertainty), the uncertainty created by the irreducible variation in these systems (variability), and finally the uncertainty associated with our value systems and management decisions (decision uncertainty). {\textbackslash}par The report examines in detail the various sources of linguistic uncertainty, epistemic uncertainty and variability in scientific endeavors and risk-related problems. It summarises probabilistic, non-probabilistic and graphical methods for treating and propagating these sources of uncertainty through risk assessment under the headings of five basic strategies: ignore it, eliminate it, envelope it, average over it or factorise it. It also examines the related problem of dependency that occurs when arithmetic operations are performed with random variables. {\textbackslash}par The principal impediment to uncertainty analysis within qualitative risk assessment is that variability and epistemic uncertainty are confounded with each other and with linguistic uncertainty. Separating the three sources of uncertainty requires, as a minimum, that linguistic uncertainty is eliminated from the problem as far as possible. Fuzzy sets and possibility theory provide a mechanism that was specifically designed to eliminate two important sources of linguistic uncertainty (vagueness and ambiguity). These sources of uncertainty, however, can also be eliminated with probability theory via carefully implemented elicitation methods and probability bounds analysis. This approach has the additional advantages of: a) being able to minimise other well known heuristics and biases in human perception and judgements of uncertain events; and, b) couching its analysis within the realms of probability theory which is likely to be more familiar to decision makers than evidence or possibility theory. {\textbackslash}par Furthermore, there are a range of issues with qualitative approaches to risk assessment that relate to the science-quality criteria of transparency, repeatability and falsifiability, and the decisionutility criteria of precision and accuracy, namely: • qualitative risk assessment predictions cannot be (in)validated with observations, and uncertainty cannot be coherently propagated through risk functions without translating qualitative metrics of likelihood or consequence into numerical metrics; • arithmetic operations, such as product, performed with linguistic descriptions of likelihood and/or consequence can be biased and non-commutative. These problems only become apparent when vagueness is eliminated from the analysis using numerical definitions of terms such as “high”, “medium” or “low”. This report uses interval analysis to show that the qualitative risk operations performed by the AGDAFF for import risk assessment lead to biased and non-commutative results; and, • the effects of dependency between risk-generating events cannot be coherently explored with qualitative descriptions of uncertain events, leading to different interpretations of observed outcomes and potentially paradoxical assumptions about the relatively likelihood of events. {\textbackslash}par The problem of epistemic uncertainty and variability in quantitative risk assessment starts with the availability of data. This report distinguishes data - observations of a process - understanding and beliefs about a process. The key to uncertainty analysis in the absence of data is elicitation. Elicitation converts beliefs into outcomes, models or parameters that enable regression and forward propagative uncertainty analysis. Again, structured elicitation techniques also provide an opportunity to avoid or minimise heuristic bias and dysfunctional group effects, and are therefore “good practice” in quantitative risk assessment. {\textbackslash}par Import risk assessment is often performed in the absence of empirical observations. Uncertainty analysis in this context can be performed using elicitation and forward uncertainty propagation methods. The key challenges associated with epistemic uncertainty and variability can be addressed or eliminated by making assumptions about the structure of the risk-generating process (the model), the shape, scale and/or location of the probability distribution(s) that represent variability and/or epistemic uncertainty in model parameters, and the nature of the dependency between the parameters of the model. These types of assumptions have an important bearing on the results of the risk assessment. The principal objectives of propagative uncertainty analysis are to report, and where practical, test the effect of these assumptions on the overall risk estimate, and in doing so achieve an honest assessment. In approaching this problem the analyst can adopt one or more of the strategies identified above, namely: • simply ignore: this is sometimes defensible for parametric uncertainty and model structure uncertainty, but only in limited circumstances. For example, model structure uncertainty can be ignored where the model or risk function is dictated by legislation or guidelines. In this context the risk assessment results are only defensible as a guide to the relative magnitude of risk but this can be useful as a risk-screening decision aid; • eliminate: this is possible for variability (and to a limited degree dependence) by either building a more complex risk model that models variability or via choosing a simpler assessment endpoint that enables a simpler risk model with a lower parameter dimension. The first approach may not be attractive in data-limited circumstances because it can increase model structure uncertainty. The latter approach is only tenable if meaningful decision criteria can be stipulated by a decision maker for the simpler endpoint; • compare and envelope: comparative strategies are akin to sensitivity analysis and seek to highlight the effect of assumptions on risk estimates. Enveloping methodologies place bounds on the best and worst estimates and seek to guarantee that the true result will lie within these bounds. Interval analysis, probability boxes and probability bounds analysis can satisfy this guarantee for variability and dependence with minimal conditions, for example, that the true value of an uncertain quantity lies within an elicited interval. Overconfident expert opinion is clearly a challenge in this regard. Info-gap theory attempts to place an upper bound on the effects of uncertainty on decisions but its recommendations may be sensitive to initial conditions. Moreover, comparison and enveloping cannot guarantee that the effects of model structure uncertainty have been completely addressed because the set of possible models is infinite. In the absence of data and statistical inference this problem is unconstrained but is best approached by consulting widely and comparing as many plausible models as is possible within the resources available to the study. Techniques such as influence diagrams, loop analysis and fuzzy cognitive maps can be helpful in this context; • average over: an analyst can average over variability and several sources of epistemic uncertainty, including model structure uncertainty, using techniques such as second-order Monte Carlo Simulation and Bayesian model averaging. Again, however, in the absence of data this problem is unconstrained and computationally more demanding than the compare and envelope strategy. The range of plausible model structures, or alternative probability density functions, that can be addressed within the resources of a single study are therefore likely to be smaller with this strategy, and in the case of model structure uncertainty it can lead to risk estimates that are incompatible with accepted theories; and. • model and factorise: this strategy is applicable to variability and dependence and in the presence of data also provides a means to identify parsimonious descriptions of cause and effect and thereby treat model structure uncertainty. Copulas and Bayesian networks can be used to treat dependence and partition different sources of variability in a risk assessment problem. These methods can be used in data-poor situations but the lack of data-based constraints can still undermine attempts to provide a systematic analysis. Moreover, the full benefits of Bayesian networks, and statistical graph theory and hierarchical modeling in general, cannot be realised in the absence of data. {\textbackslash}par Virtually all risk assessment frameworks emphasise the importance of monitoring and review, and this report emphasises that scientifically credible risk assessments should ultimately become a statistical exercise by making predictions about the risk-generating process that are testable and eventually tested against observations. Any historical distinction between uncertainty analysis and statistics is not constructive in a risk assessment context. A more useful distinction is to consider forward uncertainty propagation methods as the initial tools of uncertainty analysis that enable honest assessments to proceed before observations are made and data are collected. Thereafter, uncertainty analysis should increasingly move to an inferential mode that relies on statistics and uncertainty analysis methods to characterise and quantify variability and epistemic uncertainty in data sets relevant to the problem in hand. {\textbackslash}par A synthesis of these discussions, together with an examination of the pros and cons of different uncertainty analysis methods, suggests the following overall strategy for uncertainty analysis in import risk assessment: 1. use formal elicitation techniques to canvass the opinions, construct conceptual models and parameterize the beliefs of stakeholders and experts. Use either predictive or structural elicitation methods to convert conceptual models into statistical, qualitative and/or mechanistic models and convert beliefs about stochastic variables into numerical intervals with assigned levels of confidence; 2. ensure feedback is embedded within the elicitation procedure (to minimise the potential for misunderstanding) and apply an advocacy-like procedure to ensure that all aspects of the risk assessment are rigorously reviewed; 3. state risk-decision criteria (risk acceptability levels) in a numeric, measurable fashion for as many of the steps in the risk-generating process as is possible, including steps leading up to the overall assessment endpoint; 4. maintain plausible diverse opinions and in the first instance envelope this diversity using techniques such as loop analysis, comparisons of alternative risk functions, interval analysis, probability boxes and probability bounds analysis. If the upper bound on the subsequent risk estimate is lower than the decision criteria associated with the assessment endpoint, report the result and consider the need for monitoring strategies that enable (in)validation of as many of the steps in the risk-generating process as possible within the resources available to the assessment. If possible, collect data and use statistical inference methods to check that the risk-generating process is operating within the bounds predicted for each step of the process by the risk assessment; 5. if the lower bound on the enveloped risk estimate is higher than the decision criteria associated with the assessment endpoint consider prohibiting, stopping or otherwise mitigating the risk-generating process and if necessary repeat the risk assessment with risk management steps in place, and include within the assessment the impact of management, and the effects of decision uncertainty upon this; and, 6. if the upper and lower bounds of the enveloped risk estimate straddle the decision criteria associated with the assessment endpoint consider first the effects of dependence and the mitigating effects of positive or negative dependence. For example, a potential application of positive quadrant dependence arises in import risk assessment because the probability of detecting organisms at the border should be positively dependent on the number of organisms that arrive at the border - i.e. as the number of infected units rises so should the probability of their detection. Treating these events as independent denies the reality of inspection regimes, inflates uncertainty bounds and can lead to paradoxical simulations where large numbers of infected units are multiplied by a small probability of detection (and vice-versa) in naive simulations. {\textbackslash}par The strategy outlined above is designed to enable uncertainty analysis with the minimum amount of assumptions. The objective here is for the assessment to be roughly right rather than precisely wrong. If the enveloped predictions continue to cross the assessment endpoint then two avenues are available to the assessor and manager: • consider prohibiting or otherwise deferring the risk-generating process and the risk assessment, and collect data that enables statistical inference and a more precise empirical estimate of the risk function (statistical or mechanistic model) and/or the variables (risk factors) associated with this model; or, • use the most plausible assumptions about the model structure and its variables to provide a more precise risk prediction by modeling and/or factorising the uncertainty associated with the problem using techniques such as Bayesian Networks and second-order Monte Carlo Simulation supported by linear or non-linear estimates of dependence. {\textbackslash}par It is very important with the second option that the assumptions associated with the analysis are clearly communicated together with the effects of alternative plausible assumptions on the risk estimate where possible. It is also important that monitoring strategies are designed and implemented in order to (in)validate as many of the steps in the risk-generating process as possible and thereby enable a gradual departure from data-poor circumstances to data-rich circumstances, and a move towards the inference opportunities of modern statistical methods.},
  number = {0705A},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Hayes, K},
  month = feb,
  year = {2011},
  keywords = {import}
}

@techreport{cross_tools_2011,
  title = {Tools for {Anticipating} {Potential} {Problems} in {Biosecurity} {Applications}},
  url = {https://cebra.unimelb.edu.au/__data/assets/pdf_file/0007/2220838/0606_final-report.pdf},
  abstract = {This report provides a broad overview of techniques used in safety and reliability engineering to identify the nature and causes of risk. The report assesses the potential for these methods to be deployed in biosecurity operations, to reduce unanticipated failures effectively. It uses two case studies to illustrate them; the foot and mouth outbreak in Surrey, UK, and a hypothetical incursion of equine influenza. {\textbackslash}par The report finds that control charts and syndromic surveillance tools may be useful in border quarantine and post-border surveillance systems where routine time series data are collected. They may provide early warning of changes in the nature and frequency of risks on pathways. {\textbackslash}par Process-based methods such as Failure Mode and Effect Analysis, (FMEA), Hazard and Operability Studies (HAZOP), and Hazard and Critical Control Point analysis (HACCP) can be time-consuming but may have a place in biosecurity in assessing existing operational procedures, identifying weaknesses, and anticipating faults especially when failures are critical. For instance, HACCP may be useful for assessing the possibility of substituting one management system (or set of quarantine measures) for another, evaluating system equivalence and the potential for failures in the candidate system. {\textbackslash}par Causal analysis techniques are applied typically after a serious system failure. Examples demonstrate that complex systems are not easily identified from this type of analysis, even after the event. This is a critical point for biosecurity applications. Systems that depend on complex human factors require explicit analysis using tools developed for such situations. {\textbackslash}par ‘Human factors analysis’ aims to describe, predict, and manage human behaviour to achieve operational goals. These methods provide a framework for understanding how systems can become error-prone, and how procedures may be implemented to anticipate and remedy these situations. Application of human factors analysis to the two case studies illustrates how it may have been useful in elaborating the causes of failure and identifying systemic changes that would reduce the chances of repetition of such events. The report concludes by outlining barrier techniques, foresight and scenario planning methods that may usefully support human factors analysis.},
  number = {0606},
  institution = {Australian Centre of Excellence for Risk Analysis},
  author = {Cross, J},
  month = sep,
  year = {2011},
  keywords = {import}
}

